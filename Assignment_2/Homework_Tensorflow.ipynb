{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 32, 32, 3)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 32, 32, 3)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "from cs231n.data_utils import load_CIFAR10\n",
    "import numpy as np\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=10000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = '/home/aniket/Downloads/CS231n/assignment2/cs231n/datasets/cifar-10-batches-py/'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first initialiazed network variables and then network model\n",
    "\n",
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# setup input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None, 32,32,3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def model(X, y):\n",
    "    \n",
    "    # define our weights (e.g. init_two_layer_convnet)\n",
    "    # setup variables\n",
    "    Wconv1 = tf.get_variable(\"Wcon1\", shape=[7,7,3,32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408,10])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[10])\n",
    "    \n",
    "    # define our graph (e.g. two_layer_convnet)\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,2,2,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    h1_flat = tf.reshape(h1, [-1,5408])\n",
    "    y_out = tf.matmul(h1_flat, W1) + b1\n",
    "    return y_out\n",
    "\n",
    "y_out = model(X, y)\n",
    "\n",
    "# define our loss\n",
    "loss = tf.losses.hinge_loss(tf.one_hot(y, 10), logits=y_out)\n",
    "mean_loss = tf.reduce_mean(loss)\n",
    "\n",
    "# define optimizer\n",
    "optim = tf.train.AdamOptimizer(5e-4)\n",
    "train_step = optim.minimize(mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Iteration 0: with minibatch training loss = 8.9 and accuracy of 0.062\n",
      "Iteration 100: with minibatch training loss = 0.907 and accuracy of 0.3\n",
      "Iteration 200: with minibatch training loss = 0.725 and accuracy of 0.31\n",
      "Iteration 300: with minibatch training loss = 0.649 and accuracy of 0.25\n",
      "Iteration 400: with minibatch training loss = 0.517 and accuracy of 0.33\n",
      "Iteration 500: with minibatch training loss = 0.567 and accuracy of 0.3\n",
      "Iteration 600: with minibatch training loss = 0.534 and accuracy of 0.3\n",
      "Iteration 700: with minibatch training loss = 0.498 and accuracy of 0.38\n",
      "Epoch 1, Overall loss = 0.747 and accuracy of 0.307\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRGKmpCEiIjFT0hARkZgpaYiISMz+P8nopGxAsrR6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc878be2438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Epoch 1, Overall loss = 0.459 and accuracy of 0.382\n"
     ]
    }
   ],
   "source": [
    "def run_model(session, predict, loss_val, Xd, yd,\n",
    "              epochs=1, batch_size=64, print_every=100,\n",
    "              training=None, plot_losses=False):\n",
    "    # have tensorflow compute accuracy\n",
    "    correct_prediction = tf.equal(tf.argmax(predict,1), y)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # shuffle indicies\n",
    "    train_indicies = np.arange(Xd.shape[0])\n",
    "    np.random.shuffle(train_indicies)\n",
    "    \n",
    "    training_now = training is not None\n",
    "    \n",
    "    # setting up variables we want to compute (and optimizing)\n",
    "    # if we have a training function, add that to things we compute\n",
    "    variables = [mean_loss,correct_prediction,accuracy]\n",
    "    if training_now:\n",
    "        variables[-1] = training\n",
    "    \n",
    "    # counter \n",
    "    iter_cnt = 0\n",
    "    for e in range(epochs):\n",
    "        # keep track of losses and accuracy\n",
    "        correct = 0\n",
    "        losses = []\n",
    "        # make sure we iterate over the dataset once\n",
    "        for i in range(int(math.ceil(Xd.shape[0]/batch_size))):\n",
    "            # generate indicies for the batch\n",
    "            start_idx = (i*batch_size)%Xd.shape[0]\n",
    "            idx = train_indicies[start_idx:start_idx+batch_size]\n",
    "            \n",
    "            # create a feed dictionary for this batch\n",
    "            feed_dict = {X: Xd[idx,:],\n",
    "                         y: yd[idx],\n",
    "                         is_training: training_now }\n",
    "            # get batch size\n",
    "            actual_batch_size = yd[idx].shape[0]\n",
    "            \n",
    "            # have tensorflow compute loss and correct predictions\n",
    "            # and (if given) perform a training step\n",
    "            loss, corr, _ = session.run(variables,feed_dict=feed_dict)\n",
    "            \n",
    "            # aggregate performance stats\n",
    "            losses.append(loss*actual_batch_size)\n",
    "            correct += np.sum(corr)\n",
    "            \n",
    "            # print every now and then\n",
    "            if training_now and (iter_cnt % print_every) == 0:\n",
    "                print(\"Iteration {0}: with minibatch training loss = {1:.3g} and accuracy of {2:.2g}\"\\\n",
    "                      .format(iter_cnt,loss,np.sum(corr)/actual_batch_size))\n",
    "            iter_cnt += 1\n",
    "        total_correct = correct/Xd.shape[0]\n",
    "        total_loss = np.sum(losses)/Xd.shape[0]\n",
    "        print(\"Epoch {2}, Overall loss = {0:.3g} and accuracy of {1:.3g}\"\\\n",
    "              .format(total_loss,total_correct,e+1))\n",
    "        if plot_losses:\n",
    "            plt.plot(losses)\n",
    "            plt.grid(True)\n",
    "            plt.title('Epoch {} Loss'.format(e+1))\n",
    "            plt.xlabel('minibatch number')\n",
    "            plt.ylabel('minibatch loss')\n",
    "            plt.show()\n",
    "    return total_loss,total_correct\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"): #\"/cpu:0\" or \"/gpu:0\" \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        print('Training')\n",
    "        run_model(sess,y_out,mean_loss,X_train,y_train,1,64,100,train_step,True)\n",
    "        print('Validation')\n",
    "        run_model(sess,y_out,mean_loss,X_val,y_val,1,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Training a specific model\n",
    "\n",
    "In this section, we're going to specify a model for you to construct. The goal here isn't to get good performance\n",
    "(that'll be next), but instead to get comfortable with understanding the TensorFlow documentation and configuring \n",
    "your own model.\n",
    "\n",
    "Using the code provided above as guidance, and using the following TensorFlow documentation, specify a model with \n",
    "the following architecture:\n",
    "\n",
    "    7x7 Convolutional Layer with 32 filters and stride of 1\n",
    "    ReLU Activation Layer\n",
    "    Spatial Batch Normalization Layer (trainable parameters, with scale and centering)\n",
    "    2x2 Max Pooling layer with a stride of 2\n",
    "    Affine layer with 1024 output units\n",
    "    ReLU Activation Layer\n",
    "    Affine layer from 1024 input units to 10 outputs\n",
    "\"\"\"\n",
    "\n",
    "# clear old variables\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# define our input (e.g. the data that changes every batch)\n",
    "# The first dim is None, and gets sets automatically based on batch size fed in\n",
    "X = tf.placeholder(tf.float32, [None,32,32,3])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "def convolution_model(X, y):\n",
    "    \n",
    "    # conv1\n",
    "    Wconv1 = tf.get_variable(\"Wconv1\", shape=[7,7,3,32])\n",
    "    bconv1 = tf.get_variable(\"bconv1\", shape=[32])\n",
    "    \n",
    "    #FC1\n",
    "    W1 = tf.get_variable(\"W1\", shape=[5408, 1024])\n",
    "    b1 = tf.get_variable(\"b1\", shape=[1024])\n",
    "    \n",
    "    #FC2\n",
    "    W2 = tf.get_variable(\"W2\", shape=[1024,10])\n",
    "    b2 = tf.get_variable(\"b2\", shape=[10])\n",
    "    \n",
    "    # define Network Graph\n",
    "    a1 = tf.nn.conv2d(X, Wconv1, strides=[1,1,1,1], padding='VALID') + bconv1\n",
    "    h1 = tf.nn.relu(a1)\n",
    "    # BN\n",
    "    h1_norm = tf.layers.batch_normalization(h1, axis = 1, training=is_training)\n",
    "    # Max Pooling layer\n",
    "    h1_max_pool = tf.nn.max_pool(h1, [1,2,2,1], [1,2,2,1], 'SAME')\n",
    "    #FC1\n",
    "    h1_flat = tf.reshape(h1_max_pool, [-1, 5408])\n",
    "    a2 = tf.matmul(h1_flat, W1) + b1\n",
    "    h2 = tf.nn.relu(a2)\n",
    "    # FC2\n",
    "    y_out = tf.matmul(h2, W2) + b2\n",
    "    \n",
    "    return y_out\n",
    "\n",
    "y_out = convolution_model(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.6 ms ± 461 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "(64, 10)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Now we're going to feed a random batch into the model \n",
    "# and make sure the output is the right size\n",
    "x = np.random.randn(64, 32, 32,3)\n",
    "with tf.Session() as sess:\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        tf.global_variables_initializer().run()\n",
    "        ans = sess.run(y_out, feed_dict={X:x, is_training:True})\n",
    "        %timeit sess.run(y_out,feed_dict={X:x,is_training:True})\n",
    "        print(ans.shape)\n",
    "        print(np.array_equal(ans.shape, np.array([64, 10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
